{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.special\n",
    "import scipy.linalg\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "Y = np.loadtxt('Neuron2193.txt')\n",
    "dN = Y\n",
    "print dN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN, sigma2e, tol=1e-8, trials=1.):\n",
    "    \"\"\"MAP solution, inverse covariance matrix, and marginal loglikelihood of state-space model\n",
    "    computed using Laplace approximation around MAP state.\n",
    "\n",
    "    :param dN: Observations (K,)\n",
    "    :param sigma2e: Variance of process noise\n",
    "    :param tol: Convergence criterion on the gradient of the log-likelihood\n",
    "    :param trials: Number of trials for binomial observations (1 for Bernoulli)\n",
    "    :return: x_map, U, marginal_loglikelihood, joint_loglikelihood\n",
    "    \"\"\"\n",
    "    x = np.zeros(dN.shape)\n",
    "    dN = dN.astype(float)\n",
    "    while True:\n",
    "        # Build gradient of joint\n",
    "        d2x = np.convolve(x, [-1, 2, -1])[1:-1]\n",
    "        d2x[-1] -= x[-1]\n",
    "        G = -dN + trials * (1. / (1. + np.exp(-x))) + d2x / sigma2e\n",
    "        # Build Hessian of joint\n",
    "        D = trials / (np.exp(x) + 2. + np.exp(-x)) + 2. / sigma2e\n",
    "        D[-1] -= 1. / sigma2e\n",
    "        B = -np.ones(len(D)) / sigma2e\n",
    "        B[0] = 0.\n",
    "        U = sp.linalg.cholesky_banded((B, D), lower=False)\n",
    "        # Check convergence\n",
    "        if np.dot(G, G) < tol:\n",
    "            x_map = x\n",
    "            break\n",
    "        # Update estimate of map\n",
    "        x -= sp.linalg.cho_solve_banded([U, False], G)\n",
    "\n",
    "    # Compute joint and marginal probabilities\n",
    "    joint_loglikelihood = (np.sum(np.log(sp.special.binom(trials, dN)) + dN * x_map - trials * np.log(1 + np.exp(x_map))) -\n",
    "                           .5 * ((np.sum(np.diff(x_map)**2) + x_map[0]**2) / sigma2e + len(dN) * np.log(2*np.pi*sigma2e)))\n",
    "    marginal_loglikelihood = len(dN)/2. * np.log(2*np.pi) + joint_loglikelihood - np.sum(np.log(U[-1]))\n",
    "    return x_map, U, marginal_loglikelihood, joint_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov_from_chol_precision(U):\n",
    "    \"\"\"Given the Cholesky factorization (U) of the posterior precision matrix (J), with U^t * U = J,\n",
    "    return the tridiagonal part of the covariance matrix.\n",
    "\n",
    "    :param U: Cholesky factorization (U) of J, given as [0, A; D] where A is the upper diagonal and D the main diagonal\n",
    "    :return: Cov_tri: Tridiagonal part of the covariance matrix returned as [0, C_i,i+1; C_ii; C_i+1,i, 0]\n",
    "    \"\"\"\n",
    "    assert(U.shape[0] == 2 and U[0,0] == 0)\n",
    "    A, D = U # Unpack matrix into first (above) diagonal and diagonal\n",
    "    Cov_tri = np.zeros_like(U)\n",
    "    C, V = Cov_tri # Obtain _views_ into the first diagonal and diagonal\n",
    "    # Compute last element of diagonal\n",
    "    V[-1] = 1. / (D[-1] ** 2)\n",
    "    # Recursively compute other elements of main diagonal and first diagonal\n",
    "    for i in range(len(D)-1, 0, -1):\n",
    "        iD = 1. / D[i-1]\n",
    "        iDA = iD * A[i]\n",
    "        N = -iDA * V[i]\n",
    "        C[i] = N\n",
    "        V[i-1] = iD ** 2 - N * iDA\n",
    "    return Cov_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=1., verbose=True):\n",
    "    assert(len(sigma2e_init) == len(prior_clusters))\n",
    "    C = len(prior_clusters)\n",
    "    M, K = dN.shape\n",
    "    posterior_clusters = np.tile(prior_clusters, [M,1]).T\n",
    "    sigma2e = sigma2e_init\n",
    "    expect_log_likel_old = np.NaN\n",
    "    while True:\n",
    "        sigma2e_new = np.zeros((C, M))\n",
    "        log_prob_dNi_given_c = np.zeros((C, M))\n",
    "        for i, dN_i in enumerate(dN):\n",
    "            for c, sigma2e_c in enumerate(sigma2e):\n",
    "                x_map, U, marginal_loglik, _ = Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN_i, sigma2e_c, trials=trials)\n",
    "                Cov_tri = cov_from_chol_precision(U)\n",
    "                sigma2e_new[c,i] = (np.sum(Cov_tri[1]) + np.dot(x_map, x_map) # E[x_k^2]\n",
    "                                   + np.sum(Cov_tri[1,:-1]) + np.dot(x_map[:-1], x_map[:-1]) # E[x_{k-1}^2]\n",
    "                                   - 2 * np.sum(Cov_tri[0]) - 2 * np.dot(x_map[1:], x_map[:-1])) / K # E[x_{k-1} * x_k]\n",
    "                log_prob_dNi_given_c[c,i] = marginal_loglik\n",
    "        expect_log_likel = np.sum(posterior_clusters * log_prob_dNi_given_c)\n",
    "        if verbose:\n",
    "            print(expect_log_likel, sigma2e)\n",
    "        if (abs(expect_log_likel - expect_log_likel_old) < 1e-6 * abs(expect_log_likel_old)):\n",
    "            break\n",
    "        for c, sigma2e_new_c in enumerate(sigma2e):\n",
    "            if sigma2e_new_c < 0.05:\n",
    "                break\n",
    "        expect_log_likel_old = expect_log_likel\n",
    "        sigma2e = np.sum(posterior_clusters * sigma2e_new, axis=1) / np.sum(posterior_clusters, axis=1)\n",
    "        posterior_clusters = np.exp(log_prob_dNi_given_c - np.max(log_prob_dNi_given_c, axis=0)) * prior_clusters[:,None]\n",
    "        posterior_clusters /= np.sum(posterior_clusters, axis=0)\n",
    "        prior_clusters = np.sum(posterior_clusters, axis=1) / np.sum(posterior_clusters, axis=None)\n",
    "    return sigma2e, prior_clusters, posterior_clusters, expect_log_likel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-2596.8399760229031, array([ 0.09,  0.07]))\n",
      "(-2592.2045869781032, array([ 0.08995541,  0.07002759]))\n",
      "(-2590.7926510852203, array([ 0.08994668,  0.07001673]))\n",
      "(-2589.7609437592687, array([ 0.08993048,  0.06999986]))\n",
      "(-2589.0386671364058, array([ 0.0899081 ,  0.06997778]))\n",
      "(-2588.5431097995579, array([ 0.08988072,  0.06995146]))\n",
      "(-2588.2067972620634, array([ 0.08984943,  0.06992182]))\n",
      "(-2587.980279396299, array([ 0.08981514,  0.06988961]))\n",
      "(-2587.8291639833301, array([ 0.08977859,  0.06985546]))\n",
      "(-2587.7300665081525, array([ 0.08974036,  0.06981987]))\n",
      "(-2587.6671733615681, array([ 0.08970091,  0.06978323]))\n",
      "(-2587.6297427631748, array([ 0.08966058,  0.06974584]))\n",
      "(-2587.6104061878727, array([ 0.08961963,  0.06970793]))\n",
      "(-2587.6040473775251, array([ 0.08957826,  0.06966965]))\n",
      "(-2587.6070692310082, array([ 0.08953661,  0.06963116]))\n",
      "(-2587.6169129986624, array([ 0.08949481,  0.06959253]))\n",
      "(-2587.6317397952457, array([ 0.08945293,  0.06955384]))\n",
      "(-2587.6502166838759, array([ 0.08941103,  0.06951516]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-179cf771a644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msigma2e_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.07\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprior_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msigma2e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_log_likel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCluster_Laplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma2e_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-029482a8fa12>\u001b[0m in \u001b[0;36mCluster_Laplace\u001b[0;34m(dN, sigma2e_init, prior_clusters, trials, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma2e_c\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma2e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mx_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarginal_loglik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDo_Kalman_Likelihood_Bernoulli_LaplaceMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdN_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma2e_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mCov_tri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov_from_chol_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 sigma2e_new[c,i] = (np.sum(Cov_tri[1]) + np.dot(x_map, x_map) # E[x_k^2]\n\u001b[1;32m     16\u001b[0m                                    \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCov_tri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# E[x_{k-1}^2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b86dc26491a8>\u001b[0m in \u001b[0;36mcov_from_chol_precision\u001b[0;34m(U)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0miDA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miD\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0miDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCov_tri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sigma2e_init = np.array([0.09, 0.07])\n",
    "prior_clusters = np.array([0.5, 0.5])\n",
    "sigma2e, prior_clusters, posterior_clusters, expect_log_likel = Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Expectation of log_likelihood -----\n",
      "-2596.27218369\n",
      "---- Sigma2e -----\n",
      "[ 0.0789033   0.04969628]\n",
      "---- Prior clusters (estimated) -----\n",
      "[  1.00000000e+000   8.06606304e-295]\n",
      "---- Posterior clusters -----\n",
      "[[  1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000   1.00000000e+000   1.00000000e+000   1.00000000e+000\n",
      "    1.00000000e+000]\n",
      " [  1.59912620e-295   1.59912620e-295   3.22068555e-295   1.59912620e-295\n",
      "    1.59912620e-295   1.59912620e-295   1.49295536e-294   1.59912620e-295\n",
      "    1.59912620e-295   3.30416258e-295   4.10984222e-295   7.45411820e-295\n",
      "    2.27621413e-295   4.27358808e-295   1.59912620e-295   1.41117870e-294\n",
      "    3.30764990e-295   2.09450096e-295   5.72093936e-295   5.68569876e-295\n",
      "    9.50177239e-295   1.80466288e-294   2.69183468e-294   2.44187679e-294\n",
      "    3.19712895e-295   3.29983172e-295   9.77678194e-295   2.81408548e-295\n",
      "    8.27859255e-295   2.56518150e-295   8.00863670e-295   1.29938905e-294\n",
      "    7.58886847e-295   6.38122206e-295   7.76027636e-295   9.24891200e-295\n",
      "    1.49003430e-294   3.87837034e-294   3.52235801e-294   7.17087239e-295\n",
      "    4.11024072e-295   4.68416785e-295   2.61805727e-295   3.81255452e-295\n",
      "    7.58864362e-295]]\n"
     ]
    }
   ],
   "source": [
    "print('---- Expectation of log_likelihood -----')\n",
    "print(expect_log_likel)\n",
    "print('---- Sigma2e -----')\n",
    "print(sigma2e)\n",
    "print('---- Prior clusters (estimated) -----')\n",
    "print(prior_clusters)\n",
    "print('---- Posterior clusters -----')\n",
    "print(posterior_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(posterior_clusters.shape[0]):\n",
    "    print np.where(posterior_clusters[i,:] > 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2e_init = np.array([0.5, 0.6, 0.7])\n",
    "prior_clusters = np.array([0.33, 0.33, 0.34])\n",
    "sigma2e, prior_clusters, posterior_clusters, expect_log_likel = Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=trial1)\n",
    "print('---- Expectation of log_likelihood -----')\n",
    "print(expect_log_likel)\n",
    "print('---- Sigma2e -----')\n",
    "print(sigma2e)\n",
    "print('---- Prior clusters (estimated) -----')\n",
    "print(prior_clusters)\n",
    "print('---- Posterior clusters -----')\n",
    "print(posterior_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = pd.read_csv('cluster_train_data.csv', header=None)\n",
    "print kkk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
