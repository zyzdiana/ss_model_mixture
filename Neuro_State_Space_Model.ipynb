{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notations\n",
    "\n",
    "$(0,T]$:  The observation interval during which neuron spiking activity were recorded\n",
    "\n",
    "$N_{0,t}$: Sample path of spike times from the recorded neuron in $(0,t]$, for $t \\in (0,T]$\n",
    "\n",
    "$K$: divide $(0,T]$ into $K$ intervals with width $\\Delta = \\frac{T}{K}$ such that there is at most one spike per interval\n",
    "\n",
    "$k\\Delta$: The point at which the latent process model is evaluated, for $k = 1,...,K$\n",
    "\n",
    "$\\Delta N_k$: The number of spikes at time k.\n",
    "\n",
    "$H_K = \\{\\Delta N_{1},...,\\Delta N_{K}\\}$: history of spiking activity in $(0,K]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the 1-dimensional state space model\n",
    "\n",
    "$$\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      x_k = x_{k-1} + \\epsilon_k, \\epsilon_k \\sim N(0,\\sigma^2_{\\epsilon K}) & (a) \\\\\n",
    "      \\lambda_r(k\\Delta)\\Delta = \\frac{e^{x_k}}{1+e^{x_k}} & (b)\\\\\n",
    "      \\Delta N_{k} | x_k \\sim Bernoulli(\\lambda_r(k\\Delta)\\Delta) & (c)\n",
    "\\end{array} \n",
    "\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Data Likelihood\n",
    "\\begin{align*}\n",
    "p(N_{0,K}, x; \\theta) &= p(N_{0,K}|\\boldsymbol{x})p(\\boldsymbol{x})\\\\\n",
    "&= \\prod\\limits_{k=1}^{K}\\left\\{p(\\Delta N_{k}|x_k)\\right\\}\\prod\\limits_{k=1}^{K} p(x_k|x_{k-1}; \\sigma_{\\epsilon K}^2)\n",
    "\\end{align*}\n",
    "\n",
    "where \n",
    "\\begin{align*}\n",
    "p(x; \\theta) &= (2\\pi \\sigma_{\\epsilon K}^2)^{\\frac{-K}{2}} \\exp {\\left\\{-\\sum_{k=1}^{K} \\frac{(x_k-x_{k-1})^2}{2\\sigma_{\\epsilon K}^2}\\right\\}}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "p(N_{0,K}|x) &= \\prod\\limits_{k=1}^{K} (\\lambda_r(k\\Delta)\\Delta )^{\\Delta N_{k}} (1-(\\lambda_r(k\\Delta)\\Delta))^{1-\\Delta N_{k}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-step:\n",
    "\\begin{align*}\n",
    "Q(\\theta|\\theta^{l}) &= E\\left\\{\\log [p(N_{0,K}, x; \\theta)]|| H_K, \\theta^{(l)} \\right\\}\\\\\n",
    "&=\\int \\log p(N_{0,K}, x; \\theta) p(x|H_k,\\theta^{(l-1)}) dx\n",
    "\\end{align*}\n",
    "\n",
    "#### use Sequential Monte Carlo to sample backward smoother \n",
    "\n",
    "%% $E\\{x_k || H_k, \\theta^{(l)}\\}$, $E\\{x_k^2 || H_k, \\theta^{(l)}\\}$ and $E\\{x_k x_{k-1} || H_k, \\theta^{(l)}\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import math\n",
    "import pyparticleest.models.nlg as nlg\n",
    "import pyparticleest.simulator as simulator\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pyparticleest.utils.kalman as kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(steps, P0, Q):\n",
    "    x = numpy.zeros((steps + 1,))\n",
    "    y = numpy.zeros((steps + 1,))\n",
    "    x[0] = numpy.random.multivariate_normal((0.0,), P0)\n",
    "    y[0] = numpy.random.binomial(1,numpy.exp(x[0])/(1.0+numpy.exp(x)[0]))\n",
    "    for k in range(0, steps):\n",
    "        x[k + 1] = x[k] + numpy.random.multivariate_normal((0.0,), Q)\n",
    "        y[k + 1] = numpy.random.binomial(1,numpy.exp(x[k+1])/(1.0 + numpy.exp(x[k+1])))\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use the nlg.NonlinearGaussianInitialGaussian base class but modify the Gaussian noise of measurement. Log-pdf value of the measurement have to be changed. Furthermore, we need to override the calc_g and calc_f methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli\n",
    "class StdNonLin(nlg.NonlinearGaussianInitialGaussian):\n",
    "    # x_{k+1} = x_k  + v_k = f(x_k) + v_k,\n",
    "    # y_k = 0 + e_k = g(x_k) + e_k,\n",
    "    # x(0) ~ N(0,P0), v_k ~ N(0,Q), e_k ~ Bernoulli(\\exp(x_{k})/(1+\\exp(x_{k})))\n",
    "\n",
    "    def __init__(self, P0, Q):\n",
    "    # Set covariances in the constructor since they\n",
    "    # are constant\n",
    "        super(StdNonLin, self).__init__(Px0=P0, Q=Q)\n",
    "\n",
    "    def calc_g(self, particles, t):\n",
    "    # Calculate value of g(\\xi_t,t)\n",
    "        return numpy.zeros([len(particles),1])\n",
    "    \n",
    "    def calc_f(self, particles, u, t):\n",
    "    # Calculate value of f(xi_t,t)\n",
    "        return particles\n",
    "    \n",
    "    def measure(self, particles, y, t):\n",
    "        \"\"\"\n",
    "        Return the log-pdf value of the measurement\n",
    "        Args:\n",
    "         - particles  (array-like): Model specific representation\n",
    "           of all particles, with first dimension = N (number of particles)\n",
    "         - y (array-like):  measurement\n",
    "         - t (float): time-stamp\n",
    "        Returns:\n",
    "         (array-like) with first dimension = N, logp(y|x^i)\n",
    "        \"\"\"\n",
    "        N = len(particles)\n",
    "        lpy = numpy.empty(N)\n",
    "        g = self.calc_g(particles=particles, t=t)\n",
    " \n",
    "\n",
    "        if (g is None):\n",
    "            g = numpy.repeat(self.g.reshape((1, -1, 1)), N, 0)\n",
    "        else:\n",
    "            g = g.reshape((N, -1, 1))\n",
    "        yrep = numpy.repeat(numpy.asarray(y).reshape((1, -1, 1)), N, 0)\n",
    "        diff = yrep - g\n",
    "        \n",
    "        lpy = numpy.empty(N)\n",
    "        for i in xrange(N):\n",
    "            lpy[i] = bernoulli.logpmf(diff[i],numpy.exp(particles[i])/(1.0 + numpy.exp(particles[i])))\n",
    "            #lpy[i] =scipy.stats.binom.pmf(diff[i],1,numpy.exp(particles[i])/(1.0 + numpy.exp(particles[i])),loc=0)\n",
    "        return lpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the length of the dataset and the noise parameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 200\n",
    "P0 = 1.0 * numpy.eye(1)\n",
    "Q = 1.0 * numpy.eye(1)\n",
    "\n",
    "# Forward particles\n",
    "N = 100\n",
    "# Backward trajectories\n",
    "M = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate our model using the parameters defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = StdNonLin(P0, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.\n",
      "  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(0)\n",
    "(x, y) = generate_dataset(T, P0, Q)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simulator object using our previously instatiated model combined with the measurements y. This example doesnâ€™t use any input signals u. Use N particle for the filter, M trajectories for the smoother. Generally N>M. For the filtering algorithm use the standard bootstrap particle filter, for the smoothing use backward simulation. Indicate that the first measurement is of the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 23.4 ms, total: 2.37 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sim = simulator.Simulator(model, u=None, y=y)\n",
    "sim.simulate(N, M, filter='PF', smoother='full', meas_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the filtered estimates, and computed the weighed mean of the filtered estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(est_filt, w_filt) = sim.get_filtered_estimates()\n",
    "mean_filt = sim.get_filtered_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract smoothed estimates and mean and plot the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est_smooth = sim.get_smoothed_estimates()\n",
    "\n",
    "mean_smooth = sim.get_smoothed_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=numpy.diff(est_smooth[:,:,0]-est_smooth[:,:,0],axis=0)\n",
    "logpx = kalman.lognormpdf_scalar(diff.ravel(), Q)\n",
    "lpx=numpy.sum(logpx) / M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-37.3530823489\n"
     ]
    }
   ],
   "source": [
    "yt=numpy.repeat(numpy.asarray(y, dtype=float).reshape((-1, 1, 1)),\n",
    "                                 repeats=M, axis=1)\n",
    "logpy=bernoulli.logpmf(yt,numpy.exp(est_smooth)/(1.0+numpy.exp(est_smooth)))\n",
    "lpy=numpy.sum(logpy.ravel())/M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(T + 1), x, 'r-', linewidth=2.0, label='True')\n",
    "#plt.plot((0,) * N, est_filt[0, :, 0].ravel(), 'k.',\n",
    "#        markersize=0.5, label='Particles')\n",
    "#for t in xrange(1, T + 1):\n",
    "    #plt.plot((t,) * N, est_filt[t, :, 0].ravel(),\n",
    "    #         'k.', markersize=0.5)\n",
    "plt.plot(range(T + 1), mean_filt[:, 0], 'g--',\n",
    "         linewidth=2.0, label='Filter mean')\n",
    "plt.plot(range(T + 1), mean_smooth[:, 0], 'b--',\n",
    "         linewidth=2.0, label='Smoother mean')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse_filt = 0.0\n",
    "rmse_smooth = 0.0\n",
    "rmse2_filt = 0.0\n",
    "rmse2_smooth = 0.0\n",
    "\n",
    "err = mean_filt.ravel() - x\n",
    "rmse_filt += numpy.sqrt(numpy.mean(err ** 2))\n",
    "\n",
    "tmp = 0.0\n",
    "plt.plot((0,) * N, est_filt[0, :, 0].ravel(), 'k.', markersize=0.5, label='Particles')\n",
    "for t in xrange(1, T + 1):\n",
    "    plt.plot((t,) * N, est_filt[t, :, 0].ravel(), 'k.', markersize=0.5)\n",
    "    tmp += numpy.sum(w_filt[t] * (est_filt[t, :, 0] - x[t]) ** 2)\n",
    "rmse2_filt += numpy.sqrt(tmp / T)\n",
    "\n",
    "if (M > 0):\n",
    "    est_smooth = sim.get_smoothed_estimates()\n",
    "\n",
    "    mean_smooth = sim.get_smoothed_mean()\n",
    "    err = mean_smooth.ravel() - x\n",
    "    rmse_smooth += numpy.sqrt(numpy.mean(err ** 2))\n",
    "\n",
    "    tmp = 0.0\n",
    "    for k in xrange(M):\n",
    "        tmp += 1.0 / M * numpy.sum((est_smooth[:, k, 0].ravel() - x) ** 2)\n",
    "    rmse2_smooth += numpy.sqrt(tmp / T)\n",
    "\n",
    "plt.ioff()\n",
    "plt.plot(range(T + 1), mean_filt[:, 0], 'g--', linewidth=2.0, label='Filter mean')\n",
    "plt.plot(range(T + 1), mean_smooth[:, 0], 'b--', linewidth=2.0, label='Smoother mean')\n",
    "plt.legend(loc='best')\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in xrange(51):\n",
    "#    plt.hist(est_smooth[i,:,0], bins = 20)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
