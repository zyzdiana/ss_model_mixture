{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!python\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import cPickle as pickle\n",
    "from   random import *\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pyparticleest.utils.kalman as kalman\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.special\n",
    "import scipy.linalg\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1,'/Users/zyzrdfz/Documents/ss_model_mixture/Cython_Code')\n",
    "from fastloop import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = np.loadtxt('train_data.txt')\n",
    "Y = mat[:,1:]\n",
    "T = Y.shape[1]\n",
    "n = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3000)\n"
     ]
    }
   ],
   "source": [
    "print Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi=[0.5, 0.5]\n",
    "sigma = [0.2, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward particles\n",
    "N = 2000\n",
    "# Backward trajectories\n",
    "M = 200\n",
    "# trials\n",
    "trial = 50\n",
    "# cluster\n",
    "cluster = 2\n",
    "#iterations\n",
    "iteration = 20\n",
    "#\n",
    "l2pi = math.log(2 * math.pi)\n",
    "#\n",
    "sigma_ls = np.empty([iteration,cluster])\n",
    "pi_ls = np.empty([iteration,cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure(X, Y, trial):\n",
    "    coefficient = scipy.special.binom(trial,Y)\n",
    "    # log-pdf of p(y_t|x_t)\n",
    "    return np.log(coefficient) + X * Y - trial * np.log(1+np.exp(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(X, Q):\n",
    "    #log-pdf of p(x_t|x_{t-1})\n",
    "    return -0.5 * (l2pi + np.log(Q) + (X ** 2) / Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN, sigma2e, tol=1e-8, trials=1.):\n",
    "    \"\"\"MAP solution, inverse covariance matrix, and marginal loglikelihood of state-space model\n",
    "    computed using Laplace approximation around MAP state.\n",
    "\n",
    "    :param dN: Observations (K,)\n",
    "    :param sigma2e: Variance of process noise\n",
    "    :param tol: Convergence criterion on the gradient of the log-likelihood\n",
    "    :param trials: Number of trials for binomial observations (1 for Bernoulli)\n",
    "    :return: x_map, U, marginal_loglikelihood, joint_loglikelihood\n",
    "    \"\"\"\n",
    "    x = np.zeros(dN.shape)\n",
    "    dN = dN.astype(float)\n",
    "    while True:\n",
    "        # Build gradient of joint\n",
    "        d2x = np.convolve(x, [-1, 2, -1])[1:-1]\n",
    "        d2x[-1] -= x[-1]\n",
    "        G = -dN + trials * (1. / (1. + np.exp(-x))) + d2x / sigma2e\n",
    "        # Build Hessian of joint\n",
    "        D = trials / (np.exp(x) + 2. + np.exp(-x)) + 2. / sigma2e\n",
    "        D[-1] -= 1. / sigma2e\n",
    "        B = -np.ones(len(D)) / sigma2e\n",
    "        B[0] = 0.\n",
    "        U = sp.linalg.cholesky_banded((B, D), lower=False)\n",
    "        # Check convergence\n",
    "        if np.dot(G, G) < tol:\n",
    "            x_map = x\n",
    "            break\n",
    "        # Update estimate of map\n",
    "        x -= sp.linalg.cho_solve_banded([U, False], G)\n",
    "\n",
    "    # Compute joint and marginal probabilities\n",
    "    joint_loglikelihood = (np.sum(np.log(sp.special.binom(trials, dN)) + dN * x_map - trials * np.log(1 + np.exp(x_map))) -\n",
    "                           .5 * ((np.sum(np.diff(x_map)**2) + x_map[0]**2) / sigma2e + len(dN) * np.log(2*np.pi*sigma2e)))\n",
    "    marginal_loglikelihood = len(dN)/2. * np.log(2*np.pi) + joint_loglikelihood - np.sum(np.log(U[-1]))\n",
    "    return x_map, U, marginal_loglikelihood, joint_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoothing(T, N, Q, M, X, W):\n",
    "    w_back = np.empty(N)\n",
    "    W_BACK = np.empty([T,N])\n",
    "    smoother = np.empty([T,M])\n",
    "    multinomialsamples = np.random.multinomial(M, W[T-1,:])\n",
    "    X_nonzero = X[T-1, multinomialsamples>0]\n",
    "    smoother[T-1,:] = np.repeat(X_nonzero, multinomialsamples[multinomialsamples>0])\n",
    "\n",
    "\n",
    "    for tt in range(T-1):\n",
    "        t = T-2 - tt\n",
    "        for j in range(M):\n",
    "            w_back = W[t,:] * np.exp(gaussian(smoother[t+1,j]-X[t+1,:], Q))\n",
    "            W_BACK[t,:] = w_back/np.sum(w_back)\n",
    "            multinomialsamples = np.random.multinomial(1, W_BACK[t,:])\n",
    "            smoother[t,j] = X[t, multinomialsamples>0]\n",
    "\n",
    "\n",
    "    return smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filtering2(T, N, Q, Y, mode, variance):\n",
    "    samples = np.random.normal(0,1,[T,N])\n",
    "    X = np.reshape(np.repeat(mode,N),[T,N]) + np.reshape(np.repeat(np.sqrt(variance),N),[T,N]) * samples\n",
    "    ancestor = np.empty([T,N])\n",
    "    w = np.empty([T,N])\n",
    "    z = np.empty([T,N])\n",
    "    pi = np.empty([T,N])\n",
    "    W = np.empty([T,N])\n",
    "    ##Initialization\n",
    "    t = 0\n",
    "    w[t,:] = measure(X[t,:], Y[t], trial) + gaussian(X[t,:], Q) - gaussian(X[t,:] - mode[t], variance[t])\n",
    "    W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "    W[t,:] /= np.sum(W[t,:])\n",
    "    z[t,:] = W[t,:] * np.exp(measure(ancestor[t,:], Y[t+1], trial) )\n",
    "    pi[t,:] = z[t,:]/np.sum(z[t,:])\n",
    "    ancestor[t,:]= X[t,resample(pi[t,:])]\n",
    "    \n",
    "    for tt in range(T-2):\n",
    "        t=tt+1\n",
    "        w[t,:] = measure(X[t,:], Y[t], trial) + gaussian(X[t,:] - ancestor[tt,:], Q) - gaussian(X[t,:] - mode[t], variance[t]) - measure(ancestor[tt,:], Y[t], trial)    \n",
    "        W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "        W[t,:] /= np.sum(W[t,:])\n",
    "        z[t,:] = W[t,:] * np.exp(measure(ancestor[t,:], Y[t+1], trial) )\n",
    "        pi[t,:] = z[t,:]/np.sum(z[t,:])\n",
    "        ancestor[t,:]= X[t,resample(pi[t,:])]\n",
    "    \n",
    "    t=T-1\n",
    "    w[t,:] = measure(X[t,:], Y[t], trial) + gaussian(X[t,:] - ancestor[t-1,:], Q) - gaussian(X[t,:] - mode[t], variance[t])\n",
    "    W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "    W[t,:] /= np.sum(W[t,:])\n",
    "    z[t,:] = W[t,:]\n",
    "    pi[t,:] = z[t,:]/np.sum(z[t,:])\n",
    "    ancestor[t,:]= X[t,resample(W[t,:])]\n",
    "    \n",
    "    return X, w, W, ancestor, z, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-107d0784b563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancestor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mest_smooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancestor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloglikelihood\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-ecf1e5228dae>\u001b[0m in \u001b[0;36mfiltering2\u001b[0;34m(T, N, Q, Y, mode, variance)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancestor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mancestor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "sigmatmp = np.zeros([cluster,n])\n",
    "loglikelihood = np.empty([cluster,n])\n",
    "posterior_indicator = np.empty([cluster,n])\n",
    "for i in range(iteration):\n",
    "    for j in range(n):\n",
    "        for c in range(cluster):\n",
    "            Q = sigma[c]\n",
    "            [x_map, U, marginal_loglikelihood, joint_loglikelihood] = Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(Y[j,:], Q, 1e-8, trial) \n",
    "            mode = x_map\n",
    "            variance = U[1]\n",
    "            [X, w, W, ancestor, z, pi] = filtering2(T, N, Q, Y[j,:], mode, variance) \n",
    "            est_smooth = smoothing(T, N, Q, M, ancestor, pi)\n",
    "            loglikelihood[c,j] = np.sum(np.log(np.sum(z, axis = 1))) + np.sum(np.log(np.sum(np.exp(w), axis =1)/N))\n",
    "            posteriorcovariance = np.array(np.diff(est_smooth,axis=0))**2\n",
    "            sigmatmp[c,j] = np.sum(posteriorcovariance/(M*T))\n",
    "\n",
    "    maxloglikelihood = np.max(loglikelihood, axis=0)\n",
    "    w = np.exp(loglikelihood - maxloglikelihood)\n",
    "    likelihood= np.sum(np.log(np.sum(w*np.reshape(np.repeat(pi,20),(2,20)), axis=0))) + np.sum(maxloglikelihood)\n",
    "    print likelihood\n",
    "    posterior_indicator = np.exp(loglikelihood - np.max(loglikelihood, axis=0)) * np.reshape(np.repeat(pi,20),(cluster,20))\n",
    "    posterior_indicator = posterior_indicator/np.sum(posterior_indicator, axis=0)\n",
    "    pi = np.sum(posterior_indicator,axis=1)/np.sum(posterior_indicator)\n",
    "    sigma = np.sum(sigmatmp * posterior_indicator, axis=1)/np.sum(posterior_indicator,axis=1)\n",
    "    sigma_ls[i,:]=sigma\n",
    "    pi_ls[i,:]=pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
