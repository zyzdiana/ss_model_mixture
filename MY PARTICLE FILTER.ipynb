{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "#!python\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import cPickle as pickle\n",
    "from   random import *\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(1,'./code')\n",
    "from visualize import plot_raw_data, get_population_data, plot_results\n",
    "from EM import TransformToProb, RunEM\n",
    "import pyparticleest.models.nlg as nlg\n",
    "import pyparticleest.simulator as simulator\n",
    "import pyparticleest.utils.kalman as kalman\n",
    "from scipy.stats import bernoulli\n",
    "import pyparticleest.interfaces as interfaces\n",
    "from scipy.optimize import newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('thaldata.csv',header=None)\n",
    "Y = df.values.reshape(3000)\n",
    "T = len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward particles\n",
    "N = 100\n",
    "# Backward trajectories\n",
    "M = 30\n",
    "# \n",
    "P0 = 0.1\n",
    "Q = 0.1\n",
    "#trial\n",
    "trial = 50\n",
    "#\n",
    "coefficient = scipy.special.binom(trial,Y)\n",
    "#\n",
    "l2pi = math.log(2 * math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resample(weights):\n",
    "  n = len(weights)\n",
    "  indices = []\n",
    "  C = [0.] + [sum(weights[:i+1]) for i in range(n)]\n",
    "  u0, j = random(), 0\n",
    "  for u in [(u0+i)/n for i in range(n)]:\n",
    "    while u > C[j]:\n",
    "      j+=1\n",
    "    indices.append(j-1)\n",
    "  return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def measure(X, Y, trial, t, coefficient):\n",
    "    # log-pdf of p(y_t|x_t)\n",
    "    return np.log(coefficient[t]) + X[t,:] * Y[t] - trial * np.log(1+np.exp(X[t,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(X, a, S, t):\n",
    "    #log-pdf of p(x_t|x_{t-1})\n",
    "    return -0.5 * (l2pi + np.log(S) + ((X[t,:]-a).ravel() ** 2) / S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lognormpdf_scalar(err, S):\n",
    "    \"\"\"\n",
    "    Calculate gaussian probability density of all elements in err, when\n",
    "    err[i] ~ N(0,S) and each element in err is a scalar\n",
    "    \"\"\"\n",
    "    return -0.5 * (l2pi + np.log(S) + (err.ravel() ** 2) / S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filtering(T, N, Q, trial, coefficient):\n",
    "    ##Initialization\n",
    "    t = 0\n",
    "    X = np.empty([T,N])\n",
    "    ancestor = np.empty([T,N])\n",
    "    w = np.empty([T,N])\n",
    "    W = np.empty([T,N])\n",
    "    X[t,:] = np.random.normal(0, np.sqrt(Q), N)\n",
    "    w[t,:] = measure(X, Y, trial, t, coefficient)\n",
    "    W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "    W[t,:] /= np.sum(W[t,:])\n",
    "    ancestor[t,:]= X[t,resample(W[t,:])]\n",
    "    for tt in range(T-1):\n",
    "        t=tt+1\n",
    "        a = ancestor[tt,:]\n",
    "        X[t,:] = a + np.random.normal(0, np.sqrt(Q), N) ##f(x_t|x_{t-1}) standard deviation\n",
    "        w[t,:] = measure(X, Y, trial, t, coefficient) ##g(y_t|x_t)\n",
    "        W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "        W[t,:] /= np.sum(W[t,:])\n",
    "        ancestor[t,:]= X[t,resample(W[t,:])]\n",
    "    \n",
    "    return X, w, W, ancestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoothing(T, N, Q, trial, coefficient, M, X, W, ancestor):\n",
    "    w_back = np.empty([T,N])\n",
    "    W_BACK = np.empty([T,N])\n",
    "    smoother = np.empty([T,M])\n",
    "    for j in range(M):\n",
    "        myList = np.random.multinomial(1, W[T-1,:])\n",
    "        smoother[T-1,j] = ancestor[T-1, next((i for i, x in enumerate(myList) if x), None)]\n",
    "    for tt in range(T-1):\n",
    "        t = T-2 - tt\n",
    "        for j in range(M):\n",
    "            w_back = W[t,:] * np.exp(lognormpdf_scalar(smoother[t+1,j]-ancestor[t,:], Q))\n",
    "            W_BACK[t,:] = w_back/np.sum(w_back)\n",
    "            myList = np.random.multinomial(1, W_BACK[t,:])\n",
    "            smoother[t,j] = ancestor[t, next((i for i, x in enumerate(myList) if x), None)]\n",
    "            \n",
    "    return smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iterations\n",
    "iteration=50\n",
    "#initial_sigma\n",
    "sigma_ls = np.empty(iteration+1)\n",
    "sigma_ls[0]=0.1\n",
    "for i in range(iteration):\n",
    "    P0 = sigma_ls[i] * np.eye(1)    \n",
    "    Q = sigma_ls[i] * np.eye(1)\n",
    "    [X, w, W, ancestor] = filtering(T, N, Q, trial, coefficient)\n",
    "    est_smooth = smoothing(T, N, Q, trial, coefficient, M, X, W, ancestor)\n",
    "    posteriorcovariance=np.array(np.diff(est_smooth,axis=0))**2\n",
    "    sigma_ls[i+1] = np.sum(posteriorcovariance/(M*T)) * np.eye(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_smooth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Initialization\n",
    "t = 0\n",
    "v = np.zeros(N)\n",
    "X = np.empty([T,N])\n",
    "ancestor = np.empty([T,N])\n",
    "w = np.empty([T,N])\n",
    "W = np.empty([T,N])\n",
    "X[t,:] = np.random.normal(0, np.sqrt(P0), N)\n",
    "w[t,:] = measure(X, Y, trial, t, coefficient)\n",
    "W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "W[t,:] /= np.sum(W[t,:])\n",
    "ancestor[t,:]= X[t,resample(W[t,:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, np.sqrt(P0), ([T,N]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode = np.empty(T)\n",
    "variance = np.empty(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 s, sys: 29.6 ms, total: 2.82 s\n",
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for tt in range(T-1):\n",
    "    t=tt+1\n",
    "    #samplemean = nanmean(ancestor[tt,:])\n",
    "    #samplevariance = nanvar(ancestor[tt,:]) + Q\n",
    "    #mode = samplemean + (samplevariance)*(Y[t] - np.exp(samplemean)/(1 + np.exp(samplemean)) * trial)\n",
    "    #variance = 1.0 / (1.0/((samplevariance) + trial * np.exp(samplemean)/(1+np.exp(samplemean))**2))\n",
    "    #X[t,:] = np.random.normal(mode[tt],np.sqrt(variance[tt]), N)\n",
    "    #X[t,:] = mode + variance * noise[t,:]\n",
    "    a = ancestor[tt,:]\n",
    "    X[t,:] = a + np.random.normal(0, np.sqrt(Q), N) ##f(x_t|x_{t-1}) standard deviation\n",
    "    #w = measure(X, Y, trial, t, coefficient) + forward(X, ancestor[tt,:], Q, t) - lognormpdf_scalar(X[t,:]-mode, variance)   \n",
    "    w[t,:] = measure(X, Y, trial, t, coefficient) ##g(y_t|x_t)\n",
    "    W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "    W[t,:] /= np.sum(W[t,:])\n",
    "    ancestor[t,:]= X[t,resample(W[t,:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3141.4401146831378"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlogweight = np.max(w,axis=1)\n",
    "weight = np.exp(w - np.reshape(np.repeat(maxlogweight, N),(T, N)))\n",
    "np.sum(np.log(np.sum(weight, axis = 1)/N))+np.sum(maxlogweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.57 s, sys: 42 ms, total: 5.62 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_back = np.empty([T,N])\n",
    "W_BACK = np.empty([T,N])\n",
    "smoother = np.empty([T,M])\n",
    "for j in range(M):\n",
    "    myList = np.random.multinomial(1, W[t,:])\n",
    "    smoother[T-1,j] = ancestor[T-1, next((i for i, x in enumerate(myList) if x), None)]\n",
    "for tt in range(T-1):\n",
    "    t = T-2 - tt\n",
    "    for j in range(M):\n",
    "        w_back = W[t,:] * np.exp(lognormpdf_scalar(smoother[t+1,j]-ancestor[t,:], Q))\n",
    "        W_BACK[t,:] = w_back/np.sum(w_back)\n",
    "        myList = np.random.multinomial(1, W_BACK[t,:])\n",
    "        smoother[t,j] = ancestor[t, next((i for i, x in enumerate(myList) if x), None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_back = W[t,0] * np.exp(lognormpdf_scalar(smoother[t,0]-ancestor[t-1,:], Q))\n",
    "W_BACK[t,:] = w_back/np.sum(w_back)\n",
    "smoother[t-1,0] = ancestor[t-1, backward_resample(W_BACK[t,:], N, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('thaldata.csv',header=None)\n",
    "Y = df.values.reshape(3000)\n",
    "#mat = np.loadtxt('train_data.txt')\n",
    "#Y = mat[19,1:]\n",
    "T = len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iterations\n",
    "iteration=50\n",
    "#initial_sigma\n",
    "sigma_ls = np.empty(iteration+1)\n",
    "sigma_ls[0]=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iterations\n",
    "iteration=50\n",
    "#initial_sigma\n",
    "sigma_ls = np.empty(iteration+1)\n",
    "sigma_ls[0]=0.1\n",
    "for i in range(iteration):\n",
    "    P0 = sigma_ls[i] * np.eye(1)    \n",
    "    Q = sigma_ls[i] * np.eye(1)\n",
    "    model = StdNonLin(P0, Q)\n",
    "    sim = simulator.Simulator(model,u=None,y=Y)\n",
    "    sim.simulate(N, M, filter='PF', smoother='full', meas_first=False)\n",
    "    est_smooth = sim.get_smoothed_estimates()\n",
    "    posteriorcovariance=np.array(np.diff(est_smooth[:,:,0],axis=0))**2\n",
    "    sigma_ls[i+1] = np.sum(posteriorcovariance/(M*T)) * np.eye(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print measure(X, Y, trial, 1000, coefficient)\n",
    "print coefficient[1000]\n",
    "print forward(X, ancestor[999,:], Q, 1000)\n",
    "print lognormpdf_scalar(X[1000,:]-mode, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## for t > 0\n",
    "for tt in range(1):\n",
    "    t=tt+1\n",
    "    a = ancestor[t,:]\n",
    "    mode = a + t*Q*(Y[t] - np.exp(a)/(1 + np.exp(a)) * (Y[t] - trial * (1+np.exp(a))))\n",
    "    variance = 1.0 / (t*Q + Y[t]*np.exp(a)/(1+np.exp(a))**2 + trial * np.exp(a)*(1-np.exp(a))/(1+np.exp(a))**3)\n",
    "    X[t,:] = np.random.normal(mode,variance)\n",
    "    w[t,:] = measure(X, Y, trial, t, coefficient) + forward(X, a, Q, t) - lognormpdf_scalar(X[t,:]-mode, variance)\n",
    "    W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "    W[t,:] /= np.sum(W[t,:])\n",
    "    ancestor[t+1,:]= X[t,resample(W[t,:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.0 / (t*Q + Y[t]*np.exp(a)/(1+np.exp(a))**2 + trial * np.exp(a)*(1-np.exp(a))/(1+np.exp(a))**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.exp(a)*(1-np.exp(a))/(1+np.exp(a))**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ancestor[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal.resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    return x - ancestor + t*Q *(y[t] - np.exp(x)/(1+np.exp(x)))/(1+np.exp(x))\n",
    "\n",
    "def dh(x):\n",
    "    return 1 - t * Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def k(x):\n",
    "    return x**3 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dk(x):\n",
    "    return 3*x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x0=0.4\n",
    "print newton(k, x0, dk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.empty([T,N])\n",
    "ancestor = np.empty([T,N])\n",
    "w = np.empty([T,N])\n",
    "W = np.empty([T,N])\n",
    "X[t,:] = np.random.normal(0, np.sqrt(P0), N)\n",
    "w[t,:] = measure(X, Y, trial, t, coefficient)\n",
    "W[t,:] = np.exp(w[t,:] - np.max(w[t,:]))\n",
    "W[t,:] /= np.sum(W[t,:])\n",
    "ancestor[t,:]= X[t,resample(W[t,:])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
