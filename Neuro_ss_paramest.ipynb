{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "import pyparticleest.utils.kalman as kalman\n",
    "import pyparticleest.interfaces as interfaces\n",
    "import pyparticleest.paramest.paramest as param_est\n",
    "import pyparticleest.paramest.interfaces as pestint\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(steps, P0, Q):\n",
    "    x = numpy.zeros((steps + 1,))\n",
    "    y = numpy.zeros((steps + 1,))\n",
    "    x[0] = numpy.random.multivariate_normal((0.0,), P0)\n",
    "    y[0] = numpy.random.binomial(1,numpy.exp(x[0])/(1.0+numpy.exp(x)[0]))\n",
    "    for k in range(0, steps):\n",
    "        x[k + 1] = x[k] + numpy.random.multivariate_normal((0.0,), Q)\n",
    "        y[k + 1] = bernoulli.rvs(numpy.exp(x[k+1])/(1.0 + numpy.exp(x[k+1])))\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmean(logw, val):\n",
    "    w = numpy.exp(logw)\n",
    "    w = w / sum(w)\n",
    "    return numpy.sum(w * val.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(interfaces.ParticleFiltering, interfaces.FFBSiRS, pestint.ParamEstInterface):\n",
    "    \"\"\" x_{k+1} = x_k + v_k, v_k ~ N(0,Q),\n",
    "        y_k = e_k, e_k ~ Bernoulli(\\exp(x_{k})/(1+\\exp(x_{k}))),\n",
    "        x(0) ~ N(0,P0) \"\"\"\n",
    "\n",
    "    def __init__(self, P0, Q):\n",
    "        self.P0 = numpy.copy(P0)\n",
    "        self.Q = numpy.copy(Q)\n",
    "        self.logxn_max = kalman.lognormpdf_scalar(numpy.zeros((1,)), self.Q)\n",
    "\n",
    "    def create_initial_estimate(self, N):\n",
    "        return numpy.random.normal(0.0, numpy.sqrt(self.P0), (N,))\n",
    "\n",
    "    def sample_process_noise(self, particles, u, t):\n",
    "        \"\"\" Return process noise for input u \"\"\"\n",
    "        N = len(particles)\n",
    "        return numpy.random.normal(0.0, numpy.sqrt(self.Q), (N,))\n",
    "\n",
    "    def update(self, particles, u, noise, t):\n",
    "        \"\"\" Update estimate using 'data' as input \"\"\"\n",
    "        particles[:] = particles + noise\n",
    "\n",
    "    def measure(self, particles, y, t):\n",
    "        \"\"\" Return the log-pdf value of the measurement \"\"\"\n",
    "        return bernoulli.logpmf(y,numpy.exp(particles)/(1.0 + numpy.exp(particles)))\n",
    "\n",
    "\n",
    "    def logp_xnext(self, particles, next_part, u, t):\n",
    "        \"\"\" Return the log-pdf value for the possible future state 'next' given input u \"\"\"\n",
    "        pn = particles\n",
    "        return kalman.lognormpdf_scalar(pn.ravel() - next_part.ravel(), self.Q)\n",
    "\n",
    "    def logp_xnext_max(self, particles, u, t):\n",
    "        return self.logxn_max\n",
    "\n",
    "    def sample_smooth(self, part, ptraj, anc, future_trajs, find, ut, yt, tt, cur_ind):\n",
    "        \"\"\" Update ev. Rao-Blackwellized states conditioned on \"next_part\" \"\"\"\n",
    "        return part.reshape((-1, 1))\n",
    "\n",
    "    def set_params(self, params):\n",
    "        \"\"\" New set of parameters for which the integral approximation terms will be evaluated\"\"\"\n",
    "        self.Q = params[0] * numpy.eye(1)\n",
    "\n",
    "    def eval_logp_x0(self, particles, t):\n",
    "        \"\"\" Calculate gradient of a term of the I1 integral approximation\n",
    "            as specified in [1].\n",
    "            The gradient is an array where each element is the derivative with\n",
    "            respect to the corresponding parameter\"\"\"\n",
    "        return kalman.lognormpdf_scalar(particles, self.P0)\n",
    "    \n",
    "    def copy_ind(self, particles, new_ind=None):\n",
    "        if (new_ind is not None):\n",
    "            return numpy.copy(particles[new_ind])\n",
    "        else:\n",
    "            return numpy.copy(particles)\n",
    "\n",
    "    def eval_logp_xnext_fulltraj(self, straj, ut, tt):\n",
    "        M = straj.shape[1]\n",
    "        part = straj\n",
    "        xp = part\n",
    "        diff = part[1:] - xp[:-1]\n",
    "        logp = kalman.lognormpdf_scalar(diff.ravel(), self.Q)\n",
    "        return numpy.sum(logp) / M\n",
    "\n",
    "    def eval_logp_y_fulltraj(self, straj, yt, tt):\n",
    "        M = straj.shape[1]\n",
    "        diff = numpy.repeat(numpy.asarray(yt, dtype=float).reshape((-1, 1, 1)),\n",
    "                                 repeats=M, axis=1)\n",
    "        return numpy.sum(bernoulli.logpmf(diff.ravel(), numpy.exp(straj.ravel())/(1.0 + numpy.exp(straj.ravel())))) / M\n",
    "\n",
    "    def maximize_weighted(self, straj, alltrajs, weights):\n",
    "        return self.maximize_weighted_analytic(straj, alltrajs, weights)\n",
    "        #return self.maximize_weighted_numeric(straj, alltrajs, weights)\n",
    "        \n",
    "    def maximize_weighted_analytic(self, straj, alltrajs, weights):\n",
    "        M = alltrajs.shape[1]\n",
    "\n",
    "        tt = straj.t\n",
    "        yt = straj.y\n",
    "        part = alltrajs\n",
    "\n",
    "        xp = part\n",
    "        diff = part[1:] - xp[:-1]\n",
    "\n",
    "        werr = numpy.empty((len(alltrajs) - 1, M))\n",
    "\n",
    "        for j in xrange(len(weights)):\n",
    "            werr[:, j:j + 1] = weights[j] * diff[:, j] ** 2\n",
    "\n",
    "        Q = numpy.mean(numpy.sum(werr, axis=1))\n",
    "\n",
    "        newparams = numpy.asarray((Q,))\n",
    "        #newparams = numpy.asarray((Q,))\n",
    "        return newparams\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    numpy.random.seed(1)\n",
    "    steps = 49 #1499\n",
    "    max_iter = 4000\n",
    "    forwardnum = 1000\n",
    "    backwardnum = 500\n",
    "    P0 = 1.0 * numpy.eye(1)\n",
    "    Q = 1.0 * numpy.eye(1)\n",
    "\n",
    "    (x, y) = generate_dataset(steps, P0, Q)\n",
    "\n",
    "    t = numpy.arange(steps + 1)\n",
    "    \n",
    "    def callback_sim(estimator):\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        sest = estimator.get_smoothed_mean()\n",
    "        for k in range(sest.shape[1]):\n",
    "            plt.plot(range(steps + 1), sest[:, k], 'g-')\n",
    "\n",
    "        plt.plot(range(steps + 1), x, 'r-')\n",
    "        plt.plot(range(steps + 1), y, 'bx')\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "\n",
    "    params_it = numpy.zeros((max_iter + 1, 2))\n",
    "    Q_it = numpy.zeros((max_iter + 1))\n",
    "\n",
    "    theta_true = numpy.asarray((1.0,))\n",
    "    \n",
    "    def callback(params, Q, cur_iter):\n",
    "        params_it[cur_iter] = params\n",
    "        Q_it[cur_iter] = Q\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.clf()\n",
    "        for i in xrange(len(theta_true)):\n",
    "            plt.plot((0.0, cur_iter + 1), (theta_true[i], theta_true[i]), 'k--')\n",
    "\n",
    "        for i in xrange(len(params)):\n",
    "            plt.plot(range(cur_iter + 1), params_it[:cur_iter + 1, i], '-')\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "\n",
    "        return (cur_iter >= max_iter)\n",
    "    \n",
    "    theta0 = numpy.asarray((2.0,))\n",
    "    #theta0 = numpy.asarray((2.0,))\n",
    "    model = Model(P0, Q)\n",
    "    estimator = param_est.ParamEstimationPSAEM(model, u=None, y=y)\n",
    "    plt.ion()\n",
    "    callback(theta0, None, 0)\n",
    "    estimator.simulate(forwardnum, backwardnum, filter='pf', smoother='full', meas_first=True)\n",
    "    ctraj = numpy.copy(estimator.straj.traj)\n",
    "    filter_options = {'cond_traj': ctraj}\n",
    "\n",
    "    param = estimator.maximize(theta0, forwardnum, filter='pf',\n",
    "                       meas_first=True, max_iter=max_iter,\n",
    "                       filter_options=filter_options,\n",
    "                       callback=callback,\n",
    "                       callback_sim=callback_sim)[0]\n",
    "    plt.ioff()\n",
    "    callback(param, None, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6000848])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
