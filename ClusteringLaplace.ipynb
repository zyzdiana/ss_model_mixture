{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.special\n",
    "import scipy.linalg\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "Y = np.loadtxt('train_data_stephen.txt')\n",
    "\n",
    "trial1 = 4000\n",
    "trial2 = 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN, sigma2e, tol=1e-8, trials=1.):\n",
    "    \"\"\"MAP solution, inverse covariance matrix, and marginal loglikelihood of state-space model\n",
    "    computed using Laplace approximation around MAP state.\n",
    "\n",
    "    :param dN: Observations (K,)\n",
    "    :param sigma2e: Variance of process noise\n",
    "    :param tol: Convergence criterion on the gradient of the log-likelihood\n",
    "    :param trials: Number of trials for binomial observations (1 for Bernoulli)\n",
    "    :return: x_map, U, marginal_loglikelihood, joint_loglikelihood\n",
    "    \"\"\"\n",
    "    x = np.zeros(dN.shape)\n",
    "    dN = dN.astype(float)\n",
    "    while True:\n",
    "        # Build gradient of joint\n",
    "        d2x = np.convolve(x, [-1, 2, -1])[1:-1]\n",
    "        d2x[-1] -= x[-1]\n",
    "        G = -dN + trials * (1. / (1. + np.exp(-x))) + d2x / sigma2e\n",
    "        # Build Hessian of joint\n",
    "        D = trials / (np.exp(x) + 2. + np.exp(-x)) + 2. / sigma2e\n",
    "        D[-1] -= 1. / sigma2e\n",
    "        B = -np.ones(len(D)) / sigma2e\n",
    "        B[0] = 0.\n",
    "        U = sp.linalg.cholesky_banded((B, D), lower=False)\n",
    "        # Check convergence\n",
    "        if np.dot(G, G) < tol:\n",
    "            x_map = x\n",
    "            break\n",
    "        # Update estimate of map\n",
    "        x -= sp.linalg.cho_solve_banded([U, False], G)\n",
    "\n",
    "    # Compute joint and marginal probabilities\n",
    "    joint_loglikelihood = (np.sum(np.log(sp.special.binom(trials, dN)) + dN * x_map - trials * np.log(1 + np.exp(x_map))) -\n",
    "                           .5 * ((np.sum(np.diff(x_map)**2) + x_map[0]**2) / sigma2e + len(dN) * np.log(2*np.pi*sigma2e)))\n",
    "    marginal_loglikelihood = len(dN)/2. * np.log(2*np.pi) + joint_loglikelihood - np.sum(np.log(U[-1]))\n",
    "    return x_map, U, marginal_loglikelihood, joint_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov_from_chol_precision(U):\n",
    "    \"\"\"Given the Cholesky factorization (U) of the posterior precision matrix (J), with U^t * U = J,\n",
    "    return the tridiagonal part of the covariance matrix.\n",
    "\n",
    "    :param U: Cholesky factorization (U) of J, given as [0, A; D] where A is the upper diagonal and D the main diagonal\n",
    "    :return: Cov_tri: Tridiagonal part of the covariance matrix returned as [0, C_i,i+1; C_ii; C_i+1,i, 0]\n",
    "    \"\"\"\n",
    "    assert(U.shape[0] == 2 and U[0,0] == 0)\n",
    "    A, D = U # Unpack matrix into first (above) diagonal and diagonal\n",
    "    Cov_tri = np.zeros_like(U)\n",
    "    C, V = Cov_tri # Obtain _views_ into the first diagonal and diagonal\n",
    "    # Compute last element of diagonal\n",
    "    V[-1] = 1. / (D[-1] ** 2)\n",
    "    # Recursively compute other elements of main diagonal and first diagonal\n",
    "    for i in range(len(D)-1, 0, -1):\n",
    "        iD = 1. / D[i-1]\n",
    "        iDA = iD * A[i]\n",
    "        N = -iDA * V[i]\n",
    "        C[i] = N\n",
    "        V[i-1] = iD ** 2 - N * iDA\n",
    "    return Cov_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=1., verbose=True):\n",
    "    assert(len(sigma2e_init) == len(prior_clusters))\n",
    "    C = len(prior_clusters)\n",
    "    M, K = dN.shape\n",
    "    posterior_clusters = np.tile(prior_clusters, [M,1]).T\n",
    "    sigma2e = sigma2e_init\n",
    "    expect_log_likel_old = np.NaN\n",
    "    while True:\n",
    "        sigma2e_new = np.zeros((C, M))\n",
    "        log_prob_dNi_given_c = np.zeros((C, M))\n",
    "        for i, dN_i in enumerate(dN):\n",
    "            for c, sigma2e_c in enumerate(sigma2e):\n",
    "                x_map, U, marginal_loglik, _ = Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN_i, sigma2e_c, trials=trials)\n",
    "                Cov_tri = cov_from_chol_precision(U)\n",
    "                sigma2e_new[c,i] = (np.sum(Cov_tri[1]) + np.dot(x_map, x_map) # E[x_k^2]\n",
    "                                   + np.sum(Cov_tri[1,:-1]) + np.dot(x_map[:-1], x_map[:-1]) # E[x_{k-1}^2]\n",
    "                                   - 2 * np.sum(Cov_tri[0]) - 2 * np.dot(x_map[1:], x_map[:-1])) / K # E[x_{k-1} * x_k]\n",
    "                log_prob_dNi_given_c[c,i] = marginal_loglik\n",
    "        expect_log_likel = np.sum(posterior_clusters * log_prob_dNi_given_c)\n",
    "        if verbose:\n",
    "            print(expect_log_likel, sigma2e)\n",
    "        if (abs(expect_log_likel - expect_log_likel_old) < 1e-6 * abs(expect_log_likel_old)):\n",
    "            break\n",
    "        expect_log_likel_old = expect_log_likel\n",
    "        sigma2e = np.sum(posterior_clusters * sigma2e_new, axis=1) / np.sum(posterior_clusters, axis=1)\n",
    "        posterior_clusters = np.exp(log_prob_dNi_given_c - np.max(log_prob_dNi_given_c, axis=0)) * prior_clusters[:,None]\n",
    "        posterior_clusters /= np.sum(posterior_clusters, axis=0)\n",
    "        prior_clusters = np.sum(posterior_clusters, axis=1) / np.sum(posterior_clusters, axis=None)\n",
    "    return sigma2e, prior_clusters, posterior_clusters, expect_log_likel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "for i, dN_i in enumerate(dN):\n",
    "    print dN_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma2e_init = np.array([0.2, 0.3])\n",
    "prior_clusters = np.array([0.5, 0.5])\n",
    "sigma2e, prior_clusters, posterior_clusters, expect_log_likel = Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=trials)\n",
    "print('---- Expectation of log_likelihood -----')\n",
    "print(expect_log_likel)\n",
    "print('---- Sigma2e -----')\n",
    "print(sigma2e)\n",
    "print('---- Prior clusters (estimated) -----')\n",
    "print(prior_clusters)\n",
    "print('---- Posterior clusters -----')\n",
    "print(posterior_clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
