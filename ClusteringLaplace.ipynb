{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.special\n",
    "import scipy.linalg\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "Y = np.loadtxt('neuron_3189_16a.txt')\n",
    "dN = Y\n",
    "print dN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN, sigma2e, tol=1e-8, trials=1.):\n",
    "    \"\"\"MAP solution, inverse covariance matrix, and marginal loglikelihood of state-space model\n",
    "    computed using Laplace approximation around MAP state.\n",
    "\n",
    "    :param dN: Observations (K,)\n",
    "    :param sigma2e: Variance of process noise\n",
    "    :param tol: Convergence criterion on the gradient of the log-likelihood\n",
    "    :param trials: Number of trials for binomial observations (1 for Bernoulli)\n",
    "    :return: x_map, U, marginal_loglikelihood, joint_loglikelihood\n",
    "    \"\"\"\n",
    "    x = np.zeros(dN.shape)\n",
    "    dN = dN.astype(float)\n",
    "    while True:\n",
    "        # Build gradient of joint\n",
    "        d2x = np.convolve(x, [-1, 2, -1])[1:-1]\n",
    "        d2x[-1] -= x[-1]\n",
    "        G = -dN + trials * (1. / (1. + np.exp(-x))) + d2x / sigma2e\n",
    "        # Build Hessian of joint\n",
    "        D = trials / (np.exp(x) + 2. + np.exp(-x)) + 2. / sigma2e\n",
    "        D[-1] -= 1. / sigma2e\n",
    "        B = -np.ones(len(D)) / sigma2e\n",
    "        B[0] = 0.\n",
    "        U = sp.linalg.cholesky_banded((B, D), lower=False)\n",
    "        # Check convergence\n",
    "        if np.dot(G, G) < tol:\n",
    "            x_map = x\n",
    "            break\n",
    "        # Update estimate of map\n",
    "        x -= sp.linalg.cho_solve_banded([U, False], G)\n",
    "\n",
    "    # Compute joint and marginal probabilities\n",
    "    joint_loglikelihood = (np.sum(np.log(sp.special.binom(trials, dN)) + dN * x_map - trials * np.log(1 + np.exp(x_map))) -\n",
    "                           .5 * ((np.sum(np.diff(x_map)**2) + x_map[0]**2) / sigma2e + len(dN) * np.log(2*np.pi*sigma2e)))\n",
    "    marginal_loglikelihood = len(dN)/2. * np.log(2*np.pi) + joint_loglikelihood - np.sum(np.log(U[-1]))\n",
    "    return x_map, U, marginal_loglikelihood, joint_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov_from_chol_precision(U):\n",
    "    \"\"\"Given the Cholesky factorization (U) of the posterior precision matrix (J), with U^t * U = J,\n",
    "    return the tridiagonal part of the covariance matrix.\n",
    "\n",
    "    :param U: Cholesky factorization (U) of J, given as [0, A; D] where A is the upper diagonal and D the main diagonal\n",
    "    :return: Cov_tri: Tridiagonal part of the covariance matrix returned as [0, C_i,i+1; C_ii; C_i+1,i, 0]\n",
    "    \"\"\"\n",
    "    assert(U.shape[0] == 2 and U[0,0] == 0)\n",
    "    A, D = U # Unpack matrix into first (above) diagonal and diagonal\n",
    "    Cov_tri = np.zeros_like(U)\n",
    "    C, V = Cov_tri # Obtain _views_ into the first diagonal and diagonal\n",
    "    # Compute last element of diagonal\n",
    "    V[-1] = 1. / (D[-1] ** 2)\n",
    "    # Recursively compute other elements of main diagonal and first diagonal\n",
    "    for i in range(len(D)-1, 0, -1):\n",
    "        iD = 1. / D[i-1]\n",
    "        iDA = iD * A[i]\n",
    "        N = -iDA * V[i]\n",
    "        C[i] = N\n",
    "        V[i-1] = iD ** 2 - N * iDA\n",
    "    return Cov_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=1., verbose=True):\n",
    "    assert(len(sigma2e_init) == len(prior_clusters))\n",
    "    C = len(prior_clusters)\n",
    "    M, K = dN.shape\n",
    "    posterior_clusters = np.tile(prior_clusters, [M,1]).T\n",
    "    sigma2e = sigma2e_init\n",
    "    expect_log_likel_old = np.NaN\n",
    "    while True:\n",
    "        sigma2e_new = np.zeros((C, M))\n",
    "        log_prob_dNi_given_c = np.zeros((C, M))\n",
    "        for i, dN_i in enumerate(dN):\n",
    "            for c, sigma2e_c in enumerate(sigma2e):\n",
    "                x_map, U, marginal_loglik, _ = Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN_i, sigma2e_c, trials=trials)\n",
    "                Cov_tri = cov_from_chol_precision(U)\n",
    "                sigma2e_new[c,i] = (np.sum(Cov_tri[1]) + np.dot(x_map, x_map) # E[x_k^2]\n",
    "                                   + np.sum(Cov_tri[1,:-1]) + np.dot(x_map[:-1], x_map[:-1]) # E[x_{k-1}^2]\n",
    "                                   - 2 * np.sum(Cov_tri[0]) - 2 * np.dot(x_map[1:], x_map[:-1])) / K # E[x_{k-1} * x_k]\n",
    "                log_prob_dNi_given_c[c,i] = marginal_loglik\n",
    "        expect_log_likel = np.sum(posterior_clusters * log_prob_dNi_given_c)\n",
    "        if verbose:\n",
    "            print(expect_log_likel, sigma2e)\n",
    "        if (abs(expect_log_likel - expect_log_likel_old) < 1e-6 * abs(expect_log_likel_old)):\n",
    "            break\n",
    "        for c, sigma2e_new_c in enumerate(sigma2e):\n",
    "            if sigma2e_new_c < 0.05:\n",
    "                break\n",
    "        expect_log_likel_old = expect_log_likel\n",
    "        sigma2e = np.sum(posterior_clusters * sigma2e_new, axis=1) / np.sum(posterior_clusters, axis=1)\n",
    "        posterior_clusters = np.exp(log_prob_dNi_given_c - np.max(log_prob_dNi_given_c, axis=0)) * prior_clusters[:,None]\n",
    "        posterior_clusters /= np.sum(posterior_clusters, axis=0)\n",
    "        prior_clusters = np.sum(posterior_clusters, axis=1) / np.sum(posterior_clusters, axis=None)\n",
    "    return sigma2e, prior_clusters, posterior_clusters, expect_log_likel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-7282.9497159590755, array([ 0.1,  0.2]))\n",
      "(-7193.233690564768, array([ 0.09938138,  0.19797058]))\n",
      "(-7188.1189165505875, array([ 0.09875946,  0.19655549]))\n",
      "(-7186.6872378777625, array([ 0.09815458,  0.19518608]))\n",
      "(-7185.4579198636411, array([ 0.0975572 ,  0.19383341]))\n",
      "(-7184.2522682206009, array([ 0.09696668,  0.19249569]))\n",
      "(-7183.0606576819446, array([ 0.0963829 ,  0.19117262]))\n",
      "(-7181.8824291420588, array([ 0.09580577,  0.189864  ]))\n",
      "(-7180.7174086168197, array([ 0.09523518,  0.18856962]))\n",
      "(-7179.5654502581629, array([ 0.09467104,  0.18728926]))\n",
      "(-7178.4264113219097, array([ 0.09411326,  0.18602277]))\n",
      "(-7177.3001507570552, array([ 0.09356174,  0.18476992]))"
     ]
    }
   ],
   "source": [
    "sigma2e_init = np.array([0.1, 0.2])\n",
    "prior_clusters = np.array([0.5, 0.5])\n",
    "sigma2e, prior_clusters, posterior_clusters, expect_log_likel = Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Expectation of log_likelihood -----\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'expect_log_likel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bb0e53bafe4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---- Expectation of log_likelihood -----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpect_log_likel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---- Sigma2e -----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma2e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---- Prior clusters (estimated) -----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expect_log_likel' is not defined"
     ]
    }
   ],
   "source": [
    "print('---- Expectation of log_likelihood -----')\n",
    "print(expect_log_likel)\n",
    "print('---- Sigma2e -----')\n",
    "print(sigma2e)\n",
    "print('---- Prior clusters (estimated) -----')\n",
    "print(prior_clusters)\n",
    "print('---- Posterior clusters -----')\n",
    "print(posterior_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(posterior_clusters.shape[0]):\n",
    "    print np.where(posterior_clusters[i,:] > 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma2e_init = np.array([0.5, 0.6, 0.7])\n",
    "prior_clusters = np.array([0.33, 0.33, 0.34])\n",
    "sigma2e, prior_clusters, posterior_clusters, expect_log_likel = Cluster_Laplace(dN, sigma2e_init, prior_clusters, trials=trial1)\n",
    "print('---- Expectation of log_likelihood -----')\n",
    "print(expect_log_likel)\n",
    "print('---- Sigma2e -----')\n",
    "print(sigma2e)\n",
    "print('---- Prior clusters (estimated) -----')\n",
    "print(prior_clusters)\n",
    "print('---- Posterior clusters -----')\n",
    "print(posterior_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kkk = pd.read_csv('cluster_train_data.csv', header=None)\n",
    "print kkk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
